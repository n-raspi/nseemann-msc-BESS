{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataset from all market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dataset Timeline](media/individual_datasets_DE_timeline.png)\n",
    "<!--  Image(\"media/individual_datasets_DE_timeline.png\") -->\n",
    "\n",
    "- DA\n",
    "    - DA 60min - DE-AT-LU (ENTSO-e)\n",
    "    - DA 60min - DE-LU (ENTSO-e)\n",
    "    - DA 15min - DE-LU (ENTSO-e)\n",
    "- ID\n",
    "    - IP-index (netztransparenz)\n",
    "- FCR\n",
    "    - Procurement price 1W (SMARD)\n",
    "    - Procurement price 24h (SMARD)\n",
    "    - Procurement price 4h (SMARD)\n",
    "- aFRR cap\n",
    "    - Cost of capacity 12h (SMARD)\n",
    "    - Cost of capacity 4h (SMARD)\n",
    "- aFRR en\n",
    "    - Cost of activation 15min (SMARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day-ahead markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_202001010000-202101010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_202201010000-202301010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_202101010000-202201010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_201901010000-202001010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_202401010000-202501010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_202301010000-202401010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_201801010000-201901010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_201701010000-201801010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_201601010000-201701010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_201501010000-201601010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-AT-LU/Day-ahead Prices_201401010000-201501010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_202001010000-202101010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_202201010000-202301010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_202101010000-202201010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_201901010000-202001010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_202401010000-202501010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_202301010000-202401010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_201801010000-201901010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_201701010000-201801010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_201601010000-201701010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_201501010000-201601010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_60min/DE-LU/Day-ahead Prices_201401010000-201501010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_202001010000-202101010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_202201010000-202301010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_202101010000-202201010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_201901010000-202001010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_202401010000-202501010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_202301010000-202401010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_201801010000-201901010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_201701010000-201801010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_201601010000-201701010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_201501010000-201601010000.csv\n",
      "Importing: ../../20_data/entsoe_data/DE/DA_15min/DE-LU/Day-ahead Prices_201401010000-201501010000.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_ENTSOE_data(path, colname, areacode):\n",
    "    \"\"\"Reads all csv files in a directory and concatenates them into a single dataframe.\n",
    "    Drops rows with no currency, sets index to datetime, drops duplicate indexes, drops rows with nans and drop area code column.\n",
    "    Returns a dataframe with the specified column name\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    dirlist = os.listdir(path)\n",
    "    for i in dirlist:\n",
    "        if i.endswith(\".csv\"):\n",
    "            print('Importing:',path+i)\n",
    "            df_int = pd.read_csv(path + i)\n",
    "            df_int.dropna(subset=['Currency'], inplace=True) # Drop rows with no currency\n",
    "            if len(df_int) != 0: #If there's still rows\n",
    "                df_int.set_index('MTU (CET/CEST)', inplace=True) \n",
    "                df_int.index = pd.to_datetime(df_int.index.str.slice(0,16), format=\"%d.%m.%Y %H:%M\") # Set index to datetime\n",
    "                # print(df_int.astype('|S').dtypes)\n",
    "                # Convert all non numbers and dots to nans\n",
    "                df_int[df_int.columns[0]] = df_int[df_int.columns[0]].astype(\"string\").replace('^[^0-9.]+$', np.nan, regex=True).astype(float)\n",
    "                df_int = df_int[~df_int.index.duplicated(keep='first')] # Drop duplicate indexes\n",
    "\n",
    "                df = pd.concat([df,df_int]) # Concatenate to main dataframe\n",
    "    df.drop(columns=[areacode, 'Currency'], inplace=True)\n",
    "    df.rename(columns={'Day-ahead Price [EUR/MWh]': colname}, inplace=True)\n",
    "    df.sort_index(inplace=True) # Sort index\n",
    "    df.dropna(inplace=True) # Drop rows with nans\n",
    "    return df\n",
    "\n",
    "\n",
    "ENTSOE_DE_DATA_dir = \"../../20_data/entsoe_data/DE\"\n",
    "DA_60min_DEATLU_subdir = \"/DA_60min/DE-AT-LU/\" # 'BZN|DE-AT-LU'\n",
    "DA_60min_DELU_subdir = \"/DA_60min/DE-LU/\" # 'BZN|DE-LU'\n",
    "DA_15min_DELU_subdir = \"/DA_15min/DE-LU/\" # 'BZN|DE-LU'\n",
    "\n",
    "df_DA_60min_DEATLU = (clean_ENTSOE_data(ENTSOE_DE_DATA_dir + DA_60min_DEATLU_subdir, 'DA_60min_DEATLU', 'BZN|DE-AT-LU'))\n",
    "# print(df_DA_60min_DEATLU.index.min(), df_DA_60min_DEATLU.index.max())\n",
    "\n",
    "df_DA_60min_DELU = (clean_ENTSOE_data(ENTSOE_DE_DATA_dir + DA_60min_DELU_subdir, 'DA_60min_DELU', 'BZN|DE-LU'))\n",
    "# print(df_DA_60min_DELU.index.min(), df_DA_60min_DELU.index.max())\n",
    "\n",
    "df_DA_15min_DELU = (clean_ENTSOE_data(ENTSOE_DE_DATA_dir + DA_15min_DELU_subdir, 'DA_15min_DELU', 'BZN|DE-LU')) \n",
    "# print(df_DA_15min_DELU.index.min(), df_DA_15min_DELU.index.max())\n",
    "\n",
    "df_DA = (pd.concat([ df_DA_60min_DEATLU.asfreq('15min'), df_DA_60min_DELU.asfreq('15min'), df_DA_15min_DELU])).sort_index()\n",
    "df_DA = df_DA.groupby(df_DA.index).first() # Combine duplicate indexes (15min and 60min intervals)\n",
    "# df_DA.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-day markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IP_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01 00:00:00</th>\n",
       "      <td>43.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01 00:15:00</th>\n",
       "      <td>37.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01 00:30:00</th>\n",
       "      <td>26.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01 00:45:00</th>\n",
       "      <td>20.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01 01:00:00</th>\n",
       "      <td>33.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 22:45:00</th>\n",
       "      <td>115.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 23:00:00</th>\n",
       "      <td>114.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 23:15:00</th>\n",
       "      <td>97.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 23:30:00</th>\n",
       "      <td>99.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 23:45:00</th>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150032 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     IP_index\n",
       "2020-07-01 00:00:00     43.75\n",
       "2020-07-01 00:15:00     37.76\n",
       "2020-07-01 00:30:00     26.63\n",
       "2020-07-01 00:45:00     20.38\n",
       "2020-07-01 01:00:00     33.22\n",
       "...                       ...\n",
       "2024-10-10 22:45:00    115.49\n",
       "2024-10-10 23:00:00    114.59\n",
       "2024-10-10 23:15:00     97.92\n",
       "2024-10-10 23:30:00     99.21\n",
       "2024-10-10 23:45:00     99.75\n",
       "\n",
       "[150032 rows x 1 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netztransparenz_DATA_dir = \"../../20_data/netztransparenz\"\n",
    "IP_index = \"/IP_index/Index Ausgleichsenergiepreis [2024-10-11 17-44-33].csv\" \n",
    "df_IP_index = pd.read_csv(netztransparenz_DATA_dir + IP_index, sep=\";\") # Import csv\n",
    "\n",
    "# Set datetime index\n",
    "df_IP_index.index = pd.to_datetime(df_IP_index['Datum von'] + \" \" + df_IP_index['(Uhrzeit) von'], format=\"%d.%m.%Y %H:%M\")\n",
    "\n",
    "# Drop columns and rename\n",
    "df_IP_index.drop(columns=(df_IP_index.columns.difference(['ID AEP in €/MWh'])), inplace=True)\n",
    "df_IP_index.rename(columns={'ID AEP in €/MWh': 'IP_index'}, inplace=True)\n",
    "\n",
    "# Change comma to dot and convert to float\n",
    "df_IP_index['IP_index'] = df_IP_index['IP_index'].replace(',', '.', regex=True).astype(float)\n",
    "\n",
    "df_IP_index = df_IP_index[~df_IP_index.index.duplicated(keep='first')]\n",
    " \n",
    "# df_IP_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMARD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: Frequency_Containment_Reserve_201501010000_202101010000_Quarterhour.csv\n",
      "Importing: Frequency_Containment_Reserve_202101010000_202501010000_Quarterhour.csv\n"
     ]
    }
   ],
   "source": [
    "# SMARD import\n",
    "SMARD_dir = \"../../20_data/SMARD\"\n",
    "FCR_subdir = \"/FCR/\"\n",
    "\n",
    "df_FCR = pd.DataFrame()\n",
    "dirlist = os.listdir(SMARD_dir + FCR_subdir)\n",
    "for i in dirlist:\n",
    "    if i.endswith(\".csv\"):\n",
    "        print('Importing:', i)\n",
    "        df_int = pd.read_csv(SMARD_dir + FCR_subdir + i, sep=\";\")\n",
    "        df_int.set_index('Start date', inplace=True)\n",
    "        df_int.index = pd.to_datetime(df_int.index, format=\"%b %d, %Y %I:%M %p\")\n",
    "        df_int.drop(columns=['End date'], inplace=True)\n",
    "        df_int.rename(columns={'Volume procured [MW] Original resolutions': 'volume_procured_MW', 'Procurement price [€/MW] Original resolutions': 'procurement_price_EUR_MW'}, inplace=True)\n",
    "        df_int = df_int.replace(',', '', regex=True)\n",
    "        df_int = df_int.replace('^[^0-9.]+$', np.nan, regex=True).astype(float)\n",
    "        df_FCR = pd.concat([df_FCR,df_int]) # Concatenate to main dataframe\n",
    "df_FCR.sort_index(inplace=True) # Sort index\n",
    "\n",
    "df_FCR = df_FCR[~df_FCR.index.duplicated(keep='first')]\n",
    "# df_FCR.dropna(inplace=True) # Drop rows with nans\n",
    "#df_FCR.to_csv('fcr.csv')\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(df_FCR.index, df_FCR['procurement_price_EUR_MW'])\n",
    "# # plt.xlim(pd.Timestamp('2019-05-01'), pd.Timestamp('2023-01-01'))\n",
    "# # plt.ylim(0, 1000)\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Procurement Price (EUR/MW)')\n",
    "# plt.title('FCR Procurement Price (2020-2023)')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regelleistung data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: RESULT_OVERVIEW_CAPACITY_MARKET_FCR_2021-01-01_2021-12-31.xlsx\n",
      "Importing: RESULT_OVERVIEW_CAPACITY_MARKET_FCR_2020-01-01_2020-12-31.xlsx\n",
      "Importing: RESULT_OVERVIEW_CAPACITY_MARKET_FCR_2022-01-01_2022-12-31.xlsx\n",
      "Importing: RESULT_OVERVIEW_CAPACITY_MARKET_FCR_2023-01-01_2023-12-31.xlsx\n",
      "Importing: RESULT_OVERVIEW_CAPACITY_MARKET_FCR_2019-01-01_2019-12-31.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Regelleistung, starting July 2019, 24h\n",
    "regelleistung_dir = \"../../20_data/regelleistung\"\n",
    "FCR_subdir = \"/FCR/\"\n",
    "\n",
    "df_FCR = pd.DataFrame()\n",
    "dirlist = os.listdir(regelleistung_dir + FCR_subdir)\n",
    "\n",
    "df_FCR = pd.DataFrame()\n",
    "for i in dirlist:\n",
    "    if i.endswith(\".xlsx\"):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            df_int = pd.read_excel(regelleistung_dir + FCR_subdir + i)\n",
    "        df_int['period_start'] = df_int['DATE_FROM'] + pd.to_timedelta(df_int['PRODUCTNAME'].apply(lambda x: x.split(\"_\")[1] + \":00:00\"))\n",
    "        df_int['FCR length'] = df_int['PRODUCTNAME'].apply(lambda x: '1D' if x[7:12] == \"00_24\" else '4h')\n",
    "        print('Importing:', i)\n",
    "        if 'DE_SETTLEMENTCAPACITY_PRICE_[EUR/MW]' in df_int.columns:\n",
    "            df_int['settled price [EUR/MW]'] = df_int['DE_SETTLEMENTCAPACITY_PRICE_[EUR/MW]']\n",
    "        else:\n",
    "            df_int['settled price [EUR/MW]'] = df_int['GERMANY_SETTLEMENTCAPACITY_PRICE_[EUR/MW]']\n",
    "        df_int.drop(columns=df_int.columns.difference(['period_start', 'FCR length', 'settled price [EUR/MW]']), inplace=True)\n",
    "        df_int.set_index('period_start', inplace=True)\n",
    "        df_FCR = pd.concat([df_FCR,df_int]) # Concatenate to main dataframe\n",
    "df_FCR.sort_index(inplace=True) # Sort index\n",
    "df_FCR = df_FCR[~df_FCR.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aFRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: Automatic_Frequency_Restoration_Reserve_202101010000_202501010000_Quarterhour.csv\n",
      "Importing: Automatic_Frequency_Restoration_Reserve_201501010000_202101010000_Quarterhour.csv\n"
     ]
    }
   ],
   "source": [
    "columns_SMARD_aFRR = ['Volume activated (+) [MWh] Original resolutions',\n",
    "       'Volume activated (-) [MWh] Original resolutions',\n",
    "       'Activation price (+) [€/MWh] Original resolutions',\n",
    "       'Activation price (-) [€/MWh] Original resolutions',\n",
    "       'Volume procured (+) [MW] Original resolutions',\n",
    "       'Volume procured (-) [MW] Original resolutions',\n",
    "       'Procurement price (+) [€/MW] Original resolutions',\n",
    "       'Procurement price (-) [€/MW] Original resolutions']\n",
    "\n",
    "# SMARD import\n",
    "SMARD_dir = \"../../20_data/SMARD\"\n",
    "aFRR_subdir = \"/aFRR/\"\n",
    "\n",
    "df_aFRR = pd.DataFrame()\n",
    "dirlist = os.listdir(SMARD_dir + aFRR_subdir)\n",
    "for i in dirlist:\n",
    "    if i.endswith(\".csv\"):\n",
    "        print('Importing:', i)\n",
    "        df_int = pd.read_csv(SMARD_dir + aFRR_subdir + i, sep=\";\",low_memory=False)\n",
    "        df_int.set_index('Start date', inplace=True)\n",
    "        df_int.index = pd.to_datetime(df_int.index, format=\"%b %d, %Y %I:%M %p\")\n",
    "        df_int.drop(columns=['End date'], inplace=True)\n",
    "        df_int.rename(columns={'Volume activated (+) [MWh] Original resolutions':'aFRR_en_pos',\n",
    "        'Volume activated (-) [MWh] Original resolutions':'aFRR_en_neg',\n",
    "        'Activation price (+) [€/MWh] Original resolutions':'aFRR_en_price_pos',\n",
    "        'Activation price (-) [€/MWh] Original resolutions':'aFRR_en_price_neg',\n",
    "        'Volume procured (+) [MW] Original resolutions':'aFRR_cap_pos',\n",
    "        'Volume procured (-) [MW] Original resolutions':'aFRR_cap_neg',\n",
    "        'Procurement price (+) [€/MW] Original resolutions':'aFRR_cap_price_pos',\n",
    "        'Procurement price (-) [€/MW] Original resolutions':'aFRR_cap_price_neg'}, inplace=True)\n",
    "        df_int = df_int.replace(',', '', regex=True)\n",
    "        df_int = df_int.replace('^[^0-9.]+$', np.nan, regex=True).astype(float)\n",
    "        df_aFRR = pd.concat([df_aFRR,df_int]) # Concatenate to main dataframe\n",
    "df_aFRR.sort_index(inplace=True) # Sort index\n",
    "df_aFRR = df_aFRR[~df_aFRR.index.duplicated(keep='first')]\n",
    "#df_aFRR.dropna(inplace=True) # Drop rows with nans\n",
    "# #df_FCR.to_csv('fcr.csv')\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(df_aFRR.index, df_aFRR['aFRR_en_pos'])\n",
    "# plt.xlim(pd.Timestamp('2019-05-01'), pd.Timestamp('2023-01-01'))\n",
    "# plt.ylim(0, 1000)\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('pos en act')\n",
    "# plt.title('aFRR pos en act')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join, test, analyse and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check there are no duplicate indexes in any of the dataframes\n",
    "print(df_DA.index.duplicated().sum())\n",
    "print(df_IP_index.index.duplicated().sum())\n",
    "print(df_FCR.index.duplicated().sum())\n",
    "print(df_aFRR.index.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 days 20:00:00\n",
      "350688 - 342776\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([df_IP_index,df_aFRR,df_FCR,df_DA],axis=1)\n",
    "\n",
    "# total scope of data excluding DA datasets (as they don't overlap)\n",
    "print(combined_df.dropna(subset=combined_df.columns.difference(df_DA.columns)).index.max()- combined_df.dropna(subset=combined_df.columns.difference(df_DA.columns)).index.min())\n",
    "\n",
    "#nans with and without drop all\n",
    "print(len(combined_df),'-',len(combined_df.dropna(how='all')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy_modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
